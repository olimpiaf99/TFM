{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnm4zBn_ms-a",
        "outputId": "84b24cbe-07c6-494b-86a6-3b1294ecc568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Importing data\n",
        "\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JFn8dDim9qx"
      },
      "source": [
        "Using TensorFlow backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wMyEMqXYm_Vh"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU,SimpleRNN\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnWmbAHUnC8J",
        "outputId": "6faab140-c3f1-45d7-b9b8-660fff79298b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  1\n"
          ]
        }
      ],
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r0tZ_0p3nFop"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/train.tsv\", sep='\\t')\n",
        "validation = pd.read_csv(\"/content/drive/MyDrive/dev.tsv\", sep='\\t')\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/test_task2.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d0cPoS3LnHvb"
      },
      "outputs": [],
      "source": [
        "train = train.rename({'label ': 'label'}, axis=1) #Rename the column label\n",
        "validation = validation.rename({'label ': 'label'}, axis=1) #Rename the column label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNV9LFcKnJz8",
        "outputId": "9a25e26a-0c54-4507-9e4a-e0049dd330c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "joy          1270\n",
              "sadness       706\n",
              "anger         600\n",
              "surprise      241\n",
              "fear           67\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train = train[~train.label.str.contains(\"others\")]\n",
        "train = train[~train.label.str.contains(\"disgust\")]\n",
        "train['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwl2YR0anLR6",
        "outputId": "f9ac88f0-224e-477f-e047-4943d3cf5495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "joy          185\n",
              "sadness      103\n",
              "anger         87\n",
              "surprise      35\n",
              "fear          10\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation = validation[~validation.label.str.contains(\"others\")]\n",
        "validation = validation[~validation.label.str.contains(\"disgust\")]\n",
        "validation['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbszCDj_nWa3"
      },
      "source": [
        "# ***Preprocessing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjctVNoInZJK",
        "outputId": "da7cf89d-724f-46ef-8e66-7da496b8cbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rJSpUAk5nbBC"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YLCr721ncxB",
        "outputId": "1d0f5ec2-0d99-4e9e-a1bb-ff908ab1e2c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gxk-yBhxnegR"
      },
      "outputs": [],
      "source": [
        "import re,string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KegoZECyngKa"
      },
      "outputs": [],
      "source": [
        "def strip_links(text):\n",
        "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
        "    links         = re.findall(link_regex, text)\n",
        "    for link in links:\n",
        "        text = text.replace(link[0], ', ')    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6Pbi7NwtnhmS"
      },
      "outputs": [],
      "source": [
        "def strip_all_entities(text):\n",
        "    entity_prefixes = ['@','#', '¿', '¡']\n",
        "    for separator in  string.punctuation:\n",
        "        if separator not in entity_prefixes :\n",
        "            text = text.replace(separator,' ')\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        word = word.strip()\n",
        "        if word:\n",
        "            if word[0] not in entity_prefixes:\n",
        "                words.append(word)\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "j1Lpq2pJnj0z"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: strip_links(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "euwMz2oanlTJ"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: strip_all_entities(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hjVfcqCjnm_R"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].str.replace(r'HASHTAG', '', regex=True)\n",
        "train['tweet'] = train['tweet'].str.replace(r'USER', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BGM4M5A2nptB"
      },
      "outputs": [],
      "source": [
        "def convert_to_lower(text):\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jHWSWri1nqwJ"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: convert_to_lower(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sl2zHr-8nsHR"
      },
      "outputs": [],
      "source": [
        "def remove_numbers(text):\n",
        "    number_pattern = r'\\d+'\n",
        "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "    return without_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2wf3aHHIntLw"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: remove_numbers(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ClPIwHh4nvUA"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pAJgli7Rnwm3"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: remove_punctuation(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2_g0g6e8nzlD"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize #method that will perform text tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnEUsyaun0_J",
        "outputId": "f9662038-b3c0-44a4-98cb-faf5e6255afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3LpnkvMdn2xB"
      },
      "outputs": [],
      "source": [
        "stopword_es = nltk.corpus.stopwords.words('spanish')\n",
        "stopword = stopword_es\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    removed = []\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        if tokens[i] not in stopword:\n",
        "            removed.append(tokens[i])\n",
        "    return \" \".join(removed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f07UUCozn4Ux"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aAFbyt9un5j7"
      },
      "outputs": [],
      "source": [
        "def remove_extra_white_spaces(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wm8_UgI0n61b"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: remove_extra_white_spaces(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzRXiZWwn8dY",
        "outputId": "18d9b680-912f-4dbe-9521-1cd6a39a1eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        }
      ],
      "source": [
        "pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Imu566h1n9ro"
      },
      "outputs": [],
      "source": [
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gwF1_OEQn-_x"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                    u\"\\U0001F600-\\U0001F64F\" #emoticons\n",
        "                    u\"\\U0001F300-\\U0001F5FF\" #symbols and pictographs\n",
        "                    u\"\\U0001F680-\\U0001F6FF\" #transport and map symbols\n",
        "                    u\"\\U0001F1E0-\\U0001F1FF\" #flags (ios)\n",
        "                    u\"\\U00002702-\\U000027B0\" \n",
        "                    u\"\\U000024C2-\\U0001F251\" \n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QVs9P29poAjo"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(lambda x: remove_emoji(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrd2Hmh5oCEh",
        "outputId": "992fb4ac-0162-4930-e116-7a1b04cbbf2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: clean-text in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: ftfy<7.0,>=6.0 in /usr/local/lib/python3.7/dist-packages (from clean-text) (6.1.1)\n",
            "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from clean-text) (1.7.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n"
          ]
        }
      ],
      "source": [
        "pip install clean-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DluwKtWWoDaM",
        "outputId": "d4bfc754-0b2e-4638-c637-18da9cdcaf46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ],
      "source": [
        "from cleantext import clean\n",
        "train['tweet'] = train['tweet'].apply(lambda x: clean(x, no_emoji = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MPREboPOoqGq",
        "outputId": "31e996bf-fd7d-4a08-e9be-7703aa3f0e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet  label\n",
              "0        1                          atletico resignado perder      1\n",
              "1        2                leer proporciona mejor vision mundo      0\n",
              "2        3    amo arya stark encima todas cosas gameofthrones      0\n",
              "4        5                solo siento perdido escanos cordura      1\n",
              "5        6  solo ver intensidad agitan banderas ve quedado...      0\n",
              "...    ...                                                ...    ...\n",
              "5879  5880  imposible ver melisandre podria invernalia teo...      3\n",
              "5882  5883  dos coronaciones celebraron napoleon unico cas...      3\n",
              "5883  5884  mientras reflexionamos duro medio nueva guerra...      2\n",
              "5884  5885  fachada catedral notre dame \" salvada \" podra ...      1\n",
              "5885  5886                           sufriendo barsa si messi      0\n",
              "\n",
              "[2884 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44203751-a814-4326-a4c3-064ed0f859df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>atletico resignado perder</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>leer proporciona mejor vision mundo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>amo arya stark encima todas cosas gameofthrones</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>solo siento perdido escanos cordura</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>solo ver intensidad agitan banderas ve quedado...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5879</th>\n",
              "      <td>5880</td>\n",
              "      <td>imposible ver melisandre podria invernalia teo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5882</th>\n",
              "      <td>5883</td>\n",
              "      <td>dos coronaciones celebraron napoleon unico cas...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5883</th>\n",
              "      <td>5884</td>\n",
              "      <td>mientras reflexionamos duro medio nueva guerra...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5884</th>\n",
              "      <td>5885</td>\n",
              "      <td>fachada catedral notre dame \" salvada \" podra ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5885</th>\n",
              "      <td>5886</td>\n",
              "      <td>sufriendo barsa si messi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2884 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44203751-a814-4326-a4c3-064ed0f859df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44203751-a814-4326-a4c3-064ed0f859df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44203751-a814-4326-a4c3-064ed0f859df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "label_map = {\n",
        "    'joy ': 0,\n",
        "    'sadness ': 1,\n",
        "    'anger ': 2,\n",
        "    'surprise ': 3,\n",
        "    'fear ': 4,\n",
        "}\n",
        "\n",
        "train['label'] = train['label'].map(label_map)\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKBSETB_p4U9"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "R4yMDQhep4no"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Im-aileHp-6Y"
      },
      "outputs": [],
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train.tweet.values, train.label.values, \n",
        "                                                  stratify=train.label.values, \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.3, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFpXtA8zqDNw"
      },
      "source": [
        "# ***Simple RNN***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bmeZSfj3qEr4"
      },
      "outputs": [],
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 140\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "\n",
        "#zero pad the sequences\n",
        "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "\n",
        "word_index = token.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo97r8uBqIfg",
        "outputId": "d1f6351b-be03-461b-df12-16c0d973637b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 140, 300)          2391900   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100)               40100     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,432,101\n",
            "Trainable params: 2,432,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 209 ms, sys: 50.7 ms, total: 259 ms\n",
            "Wall time: 477 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     input_length=max_len))\n",
        "    model.add(SimpleRNN(100))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyULEtc1qXzg",
        "outputId": "6347fc03-78c4-417d-f45d-86b8a59e0f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 7s 135ms/step - loss: 0.0744 - accuracy: 0.2438 - f1_m: 0.7124 - precision_m: 0.5599 - recall_m: 0.9939\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 4s 132ms/step - loss: -0.3866 - accuracy: 0.2557 - f1_m: 0.7226 - precision_m: 0.5698 - recall_m: 0.9976\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 6s 187ms/step - loss: -2.1694 - accuracy: 0.3974 - f1_m: 0.7970 - precision_m: 0.6783 - recall_m: 0.9871\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 4s 131ms/step - loss: -4.8825 - accuracy: 0.5104 - f1_m: 0.8657 - precision_m: 0.7723 - recall_m: 0.9933\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 4s 133ms/step - loss: -8.1249 - accuracy: 0.6318 - f1_m: 0.9545 - precision_m: 0.9182 - recall_m: 0.9954\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff501a7c9d0>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync) #Multiplying by Strategy to run on TPU's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFT8ymYHssfw"
      },
      "source": [
        "LSTM's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shGH30YHss3t",
        "outputId": "92130823-620f-4a1b-acb6-94cc9b90d02f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 140, 300)          2391900   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               160400    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,552,401\n",
            "Trainable params: 160,501\n",
            "Non-trainable params: 2,391,900\n",
            "_________________________________________________________________\n",
            "CPU times: user 256 ms, sys: 4.8 ms, total: 261 ms\n",
            "Wall time: 253 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    \n",
        "    # A simple LSTM with glove embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "\n",
        "    model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YqUhimTs6kX",
        "outputId": "fde566b5-c3e7-4d1a-e005-df06b2d45c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 25s 652ms/step - loss: 0.1585 - accuracy: 0.2483 - f1_m: 0.7266 - precision_m: 6562500.0000 - recall_m: 0.9856\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 21s 671ms/step - loss: -0.0302 - accuracy: 0.2448 - f1_m: 0.7151 - precision_m: 0.5582 - recall_m: 1.0000\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 21s 645ms/step - loss: -0.0327 - accuracy: 0.2448 - f1_m: 0.7120 - precision_m: 0.5569 - recall_m: 1.0000\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 30s 946ms/step - loss: -0.0260 - accuracy: 0.2448 - f1_m: 0.7159 - precision_m: 0.5595 - recall_m: 1.0000\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 23s 704ms/step - loss: -0.0373 - accuracy: 0.2448 - f1_m: 0.7168 - precision_m: 0.5599 - recall_m: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4feb20b90>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I9u2O50tNog"
      },
      "source": [
        "GRU's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoT7sn1AtPXn",
        "outputId": "27cb0564-818b-4e67-9fd3-95293a2b555b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 140, 300)          2391900   \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 140, 300)         0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 300)               540900    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 301       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,933,101\n",
            "Trainable params: 541,201\n",
            "Non-trainable params: 2,391,900\n",
            "_________________________________________________________________\n",
            "CPU times: user 266 ms, sys: 5.07 ms, total: 271 ms\n",
            "Wall time: 254 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # GRU with glove embeddings and two dense layers\n",
        "     model = Sequential()\n",
        "     model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "     model.add(SpatialDropout1D(0.3))\n",
        "     model.add(GRU(300))\n",
        "     model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m]) \n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raxXc1cCtRgH",
        "outputId": "ecbd5273-a322-4bcb-e0bc-440d93f95b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 64s 2s/step - loss: -0.4663 - accuracy: 0.2488 - f1_m: 0.7231 - precision_m: 5625000.0000 - recall_m: 0.9840\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 55s 2s/step - loss: -0.1002 - accuracy: 0.2448 - f1_m: 0.7151 - precision_m: 0.5590 - recall_m: 1.0000\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 58s 2s/step - loss: -0.0943 - accuracy: 0.2448 - f1_m: 0.7141 - precision_m: 0.5577 - recall_m: 1.0000\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 56s 2s/step - loss: -0.0966 - accuracy: 0.2448 - f1_m: 0.7149 - precision_m: 0.5595 - recall_m: 1.0000\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 58s 2s/step - loss: -0.0997 - accuracy: 0.2448 - f1_m: 0.7154 - precision_m: 0.5607 - recall_m: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4ff56d050>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtD1mLG2tlhH"
      },
      "source": [
        "Bi-Directional RNN's"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create an embedding matrix for the words we have in the dataset\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))"
      ],
      "metadata": {
        "id": "XclCgE-o3xMl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFQjAsNPtnEX",
        "outputId": "4f07323e-b78d-46f8-c45b-16563fc87461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 140, 300)          2391900   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 600)              1442400   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 601       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,834,901\n",
            "Trainable params: 1,443,001\n",
            "Non-trainable params: 2,391,900\n",
            "_________________________________________________________________\n",
            "CPU times: user 662 ms, sys: 28.5 ms, total: 690 ms\n",
            "Wall time: 826 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # A simple bidirectional LSTM with glove embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "    model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
        "\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy',f1_m,precision_m, recall_m]) \n",
        "    \n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFGcQCn4tpDP",
        "outputId": "1dd0c5f0-37ec-41ad-ba2b-95acf96af3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 60s 2s/step - loss: 0.1152 - accuracy: 0.2517 - f1_m: 0.7283 - precision_m: 6250000.0000 - recall_m: 0.9866\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 48s 2s/step - loss: -0.0109 - accuracy: 0.2448 - f1_m: 0.7142 - precision_m: 0.5582 - recall_m: 1.0000\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 52s 2s/step - loss: 0.0015 - accuracy: 0.2448 - f1_m: 0.7154 - precision_m: 0.5595 - recall_m: 1.0000\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 48s 2s/step - loss: -0.0031 - accuracy: 0.2448 - f1_m: 0.7128 - precision_m: 0.5573 - recall_m: 1.0000\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 48s 1s/step - loss: -0.0050 - accuracy: 0.2448 - f1_m: 0.7164 - precision_m: 0.5595 - recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd7504accd0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}